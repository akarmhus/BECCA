xlim = c(-.1,.1),
labeltype = "custom",
custom.labels = name_26,
main = "Difference in topic proportions: urban vs. rural",
xlab = "Rural ... Urban")
plot.estimateEffect(int_effects,
covariate = "DQ6.Where.do.you.live.",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.2,.2),
main = "Ethnicity/International Relations by region",
xlab = "Topic Proportions")
plot.estimateEffect(int_effects,
covariate = "DQ6.Where.do.you.live.",
moderator = "DQ5.Live",
moderator.value = "urban area",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.2,.2),
main = "Ethnicity/International Relations by region (urban areas only)",
xlab = "Topic Proportions")
plot.estimateEffect(int_effects,
covariate = "DQ6.Where.do.you.live.",
moderator = "DQ5.Live",
moderator.value = "rural area",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.2,.2),
main = "Ethnicity/International Relations by region (rural areas only)",
xlab = "Topic Proportions")
```
# Discussion
It should be noted at the outset, that for the various regression techniques implemented to model the relationships between SenseMaker® signification and demographics, and STM topics and demographics, the adjusted-R2 was consistently and extremely low. A mean of `r format(mean_rsqrd,3)` was recorded for the 12 models regressing each level of the "Story Involves" variable over demographic information. At first this seemed curious, given many healthy estimates, standard errors and p-values, but on reflection given the unique way in which the data was collected, this is perhaps to be expected. Were I to walk out into the street now, and ask a passer-by to "tell me story" rather than ask her directly what the local council ought to do about traffic in the town centre, her response will likely be conditioned by whether or not her bus was time this morning, what she'd done that weekend, or whether or not she'd had a cooked breakfast, just as much as her income bracket, ethnicity or education.
SenseMaker® asks the researcher to abandon the idea of shepherding participants towards some purportedly useful, well-defined response variable, and make their own one up - so that it exhibits a high variance is perhaps unsurprising. Because we would expect the simple everyday phenomena described above - so stochastic and uninterpretable that statisticians would generally classify it as noise - to have an abnormally significant effect on the responses, it is reasonable to assume that a model which explains most of the variance in undirected human conversation is slightly overreaching. This is not to say the modelling micronarratives is useless, a statistically significant relationship between two variables is still useful for an explanatory research question, even if a predictive model would be wildly inaccurate. But is does become difficult to reliably claim that no important predictors have been omitted.
The greatest benefit of the exploring the narratives was perhaps the ability to observe social life often in a more granular, anecdotal form. Often the National Consultation and SenseMaker® would point to the same phenomena, but express them in very different ways. For instance, to say that the "human qualities of state officials" could be improved is one thing, but to hear, as one respondent indicated:
> *"I work as a taxi driver. In the evening we with the friend went taksovat. And suddenly we were stopped by traffic police. Because of not wearing a seat belt, they have been fined. My friend began to interfere with them. Traffic police got angry and drove his car. Said that he there paid the penalty. We thought because of our nationality we have done so."*
represents a much more intimate, telling reproduction of the same thing. In this form, we learn how racism transmitted through a power relationship manifested in a negative experience, how the law is used as a pretext for discrimination. The ability the observe the causal progression of events - encounter, resistance, confrontation - is a level of depth generally garnered only through resource-intensive, qualitative methods such as process tracing or ethnography.
In an essay seemingly less intended for a machine learning audience in the Harvard Business Review, (Blei, 2012) asks the reader to "imagine searching and exploring documents based on the themes that run through them. We might "zoom in" and "zoom out" to find specific or broader themes; we might look at how those themes changed through time or how they are connected to each other". The utility of this to the development researcher will naturally depend on the question at hand, but the capability to use quantitative text analysis to impose structure on data, so that one can rapidly navigate to this level of depth represents a significant innovation.
Though the narratives made for an excellent resource, self-signification with SenseMaker® proved quite a delicate tool. Significant relationships between the signifiers were often hard to come by, and interesting ones even more so. Partly this is a reflection of sample size, and missingness in the triads that made them unworkable, but it also became apparent that their utility is incredibly sensitive to the framework respondents are presented with. When the content of the narratives is unobserved, as it is for the researcher designing the framework, specifying questions that make coherent sense in every context whilst keeping their investigative teeth sharp becomes a powerful trade-off. In this respect, the National Consultation and STM performed much better because both methods inductively derive the structure of the data from the data itself. One might say that SenseMaker® permits respondents to define the distribution of the data, in that they choose their responses, but how it is hierarchical organised remains the realm of researcher - a major caveat if one is trying to claim "participant-driven" development research. Perhaps allowing textual self-signification guided by a question, would hand some liberty back to participants, though this would likely increase the time-costs of data collection - SenseMaker®'s flagship strength.
A final observation, raises a fascinating dilemma about the theoretical compatibility of topic modelling and the conceptual basis of sustainable development. STM works by trying to separate topics out, maximising their exclusivity. But when the content of topics was investigated it became increasingly clear that even seemingly unrelated topics such as water and tajikistan were in fact inextricably related to due to unanticipated phenomena, in this case water supplies spanning national borders. This presents us with a conundrum. On the one hand we have found a substantively interesting phenomenon. On the other, the decision to use an algorithm to separate these topics is undermined by the simple fact, that they are not separate, they are fundamentally interrelated. How does one decide whether the topic labelled "university/corruption" is poorly defined, or the prevalence of stories describing bribes in the education system make it a sensible, coherent whole? It might suit our intuition better that water and infrastructure are "one issue" and it is thus "semantically coherent" that they subsumed under the same topic by STM, but if the same thing occurred for water and tajikistan we might be inclined to say these are "two related issues", but separate. We might be right in a sense, if foreign affairs is also related tajikistan but not to water, but this simply brings us round to the same problem - no one topic is an island unto itself.
From this perhaps we should take two things. Firstly, that separating out data in maximally-exclusive topics is antithetical to an understanding of development which by contrast, emphasises the complex and dynamic interplay of different development themes. But secondly, and on a brighter note, it was the failure of the STM model to generate these "exclusive" topics, that brought the interesting phenomenon in the data to our attention. By relying on structure in the data that is mathematical rather than semantic in nature, our assumptions to the semantic relationships between topics are more likely to be challenged. In this respect, a flawed STM - one that refuses to conform to our preconceived notions of exclusivity and semantic coherence - might be as useful to us as a successful one.
# Conclusion
As a tool of data collection, SenseMaker® represents a promising asset for development research. Whilst the self-signification is element is perhaps stronger as a concept at this stage than it is in implementation, the micronarratives are a rich and flexible data source that promises to make the admirable notion of "bottom-up" development research into a feasible reality. The utility of narrative data in itself will depend on the research question at hand, but the reduction of time, access and financial barriers are difficult to ignore under any circumstances. In many ways STM provides the analytical depth that SenseMaker® lacks on its own, though the focus on topic prevalence over topic content (to a great extent a computational necessity) slightly diminishes its inferential power.
# Bibliography
Arora, S., Ge, R., Halpern, Y., Mimno, D., Moitra, A., Sontag, D., & Wu, Y. (2013). A Practical Algorithm for Topic Modeling with Provable Guarantees. Proceedings of The 30th International Conference on Machine Learning, (pp. 280-288).
Autesserre, S. (2012). Dangerous tales: dominant narratives on the Congo and their unintended consequences. African Affairs, 202-22.
Bell, K. E. (2013). Raising Africa?: Celebrity and the Rhetoric of the White Saviour. Journal of Multidisciplinary International Studies, 10(1).
Blei, D. (2012). Probabilistic Topic Models. Journal of the Association of Computational Machinery, 55(4), 77-84.
Blei, D., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet Allocation. Journal of Machine Learning Research, 3, 993-1022.
Chang, H.-J. (2003). Kicking Away the Ladder: Infant Industry Promotion in Historical Perspective. Oxford Development Studies, 31(1), 21-32.
Chang, J., Boyd-Graber, J., Wang, C., Gerrish, S., & Blei, D. E. (2009). Reading Tea Leaves: How Humans Interpret Topic Models. Advances in Neural Information Processing Systems, (pp. 288-296).
Clark, J. (1992). Policy influence, lobbying and advocacy. In M. Edwards, & D. Hulme, Making a Difference: NGOs and Development in a Changing World. London: Earthscan.
Collins, K. (2011). Kyrgyzstan's Latest Revolution. Journal of Democracy, 22(3), 150-164.
Dickey, J. (1983). Multiple hypergeometric functions: Probabilistic interpretations and statistical uses. Journal of the American Statistical Association, 78, 628-637.
Easterly, W. (2006). The White Man's Burden: Why the West's Efforts to Aid the Rest Have Done So Much Ill and So Little Good. New York: Basic Books.
Easterly, W. (2013). The tyranny of experts : economists, dictators, and the forgotten rights of the poor. Oxford: Oxford University Press.
Edwards, M. (1993). 'Does the doormat influence the boot?': Critical Thoughts on UK NGOs and International Advocacy. Development in Practice, 3(3), 163-175.
Fukuda-Parr, S. (2004). Millenium Development Goals: Why They Matter. Global Governance, 10(4), 395-402.
Gerring, J. (2001). Social Science Methodology: A Unified Framework. Cambridge: Cambridge University Press.
Halperin, S., & Heath, O. (2012). Political Research: Methods and Practical Skills. Oxford: Oxford University Press.
Kramp, K. M. (2004). Exploring life and experience through narrative inquiry. In K. deMarrais, & S. Lapan, Foundations for research: methods of inquiry in education and the social sciences (pp. 103-12). Mahwah, New Jersey: Lawrence Erlbaum.
Lynam, T., & Fletcher, C. (2015). Sensemaking: A Complexity Perspective. Ecology and Society, 20(1), 65-79.
Muchina, O. (1995, October-December). Qualitative indicators of transformational development. Together, 3-5.
Nyamugasira, W. (1998). NGOs and Advocacy: How Well Are The Poor Represented? Development in Practice, 8(3), 297-308.
Pitkin, H. (1972). The Concept of Representation. London: Cambridge University Press.
Ravallion, M. (2008). Doing Impact Evaluation No. 11: Evaluation in the Practice of Development. World Bank.
Rehfeld, A. (2006). Towards a General Theory of Political Representation. Journal of Politics, 68(1), 1-21.
Roberts, M. E., Stewart, B. M., Tingley, D., Lucas, C., Leder-Luis, J., Gadarian, S. K., . . . Rand, D. G. (2014). Structural Topic Models for Open-Ended Survey Responses. American Journal of Political Science, 58(4), 1064-1082.
Roberts, M., Stewart, B. E., & Tingley, D. (2016). Navigating the Local Modes of Big Data: The Case of Topic Models. In Data Analytics in Social Science, Government, and Industry. New York: Cambridge University Press.
Rubenstein, J. (2014). The Misuse of Power, Not Bad Representation: Why It's Beside The Point That Nobody Elected Oxfam? The Journal of Political Philosophy, 22(2), 204-230.
Said, E. (1978). Orientalism. London: Routledge and Kegan Paul.
Schreier, M. (2012). Will Qualitative Content Analysis Work For Me? Decision Aids. In Qualitative Content Analysis In Practice (pp. 37-57). London: Sage.
Schwartz-Shea, P., & Yanow, D. (2012). Interpretive Research Design: Concepts and Processes. New York: Routledge.
Seay, L. (2012). What's Wrong with Dodd-Frank 1502? Conflict Minerals, Civilian Livelihoods, and the Unintended Consequences of Western Advocacy (Working Paper). Centre for Global Development.
Sen, A. (1999). Development as Freedom. Oxford: Oxford University Press.
Snowden, D. (2002). Complex Acts of Knowing: Paradox and Descriptive Self-Awareness. Journal of Knowledge Management, 6(2), 100-111.
Snowden, D., & Boone, M. (2007). A Leader's Framework for Decision Making. Harvard Business Review, 85(11), 68-76.
Stacey, R. D. (2001). Complex responsive processes in organizations: Learning and knowledge creation. New York: Routledge.
Stiglitz, J. (2001). Financial Markets and Development. Oxford Review of Economic Policy, 5(4), 55-68.
Taddy, M. A. (2012). On Estimation and Selection for Topic Models.
UN Development Group. (2012). Post-2015 Development Agenda: Guidelines for Country Dialogues. Retrieved from beyond2015.org: http://www.beyond2015.org/sites/default/files/Post%202015%20Guidelines%20ENG1.pdf
UN in the Kyrgyz Republic. (2013, October 2). Findings of the Post-2015 Development Agenda National Consultations in the Kyrgyz Republic. Retrieved from UN in the Kyrgyz Republic: http://www.un.org.kg/index2.php?option=com_resource&task=show_file&id=23133
United Nations. (2013). Third Report on Progress Towards Achieveing the Millenium Developmetnt Goals. Bishkek: United Nations in the Kyrgyz Republic.
Wachtel, A. (2013). Kyrgyzstan between democratization and ethnic intolerance. Nationalities Papers: The Journal of Nationalism and Ethnicity, 41(3), 971-986.
Wagner, W., & Hayes, N. (2005). Everyday discourse and common sense. The theory of social representations. New York: Palgrave, New York.
\newpage
# Appendices
```{r, echo=FALSE,results='asis'}
print(xtable(security, caption = "Stories involving Security"),comment=FALSE)
print(xtable(education, caption = "Stories involving Education"),comment=FALSE)
print(xtable(violence, caption = "Stories involving Violence"),comment=FALSE)
print(xtable(justice[1:8,], caption = "Stories involving Justice"),comment=FALSE)
print(xtable(human_rights, caption = "Stories involving Human Rights"),comment=FALSE)
print(xtable(conflict, caption = "Stories involving Conflict"),comment=FALSE)
print(xtable(relations, caption = "Stories involving Int. Relations"),comment=FALSE)
print(xtable(other, caption = "Stories involving Other"),comment=FALSE)
plot.estimateEffect(effects,
covariate = "DQ2.Gender",
topics = 1:K,
method = "difference",
cov.value1 = "male",
cov.value2 = "female",
xlim = c(-.1,.1),
labeltype = "custom",
custom.labels = name_26,
main = "Difference in topic proportions by Gender",
xlab = "Female ... Male")
plot.estimateEffect(effects,
covariate = "DQ5.Live",
topics = 1:K,
method = "difference",
cov.value1 = "urban area",
cov.value2 = "rural area",
xlim = c(-.1,.1),
labeltype = "custom",
custom.labels = name_26,
main = "Difference in topic proportions: urban vs. rural",
xlab = "Rural ... Urban")
x <- levels(droplevels(meta$DQ6.Where.do.you.live.))
x <- x[c(2,5,6,4,1,3,7)]
regions <- NULL
for (i in 1:7){
regions <- c(regions,rep(x[i],3))
}
plot.estimateEffect(effects,
covariate = "DQ6.Where.do.you.live.",
topics = c(6,9,10),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.05,.2),
main = "Infrastructural Concerns by Region",
xlab = "Topic Proportions",
linecol = rep(1:3,3))
plot.estimateEffect(effects,
covariate = "DQ6.Where.do.you.live.",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.05,.2),
main = "Ethnicity/International Relations by region",
xlab = "Topic Proportions",
linecol = rep(1:3,3))
plot.estimateEffect(effects,
covariate = "DQ5.Live",
topics = 1:K,
method = "difference",
cov.value1 = "urban area",
cov.value2 = "rural area",
xlim = c(-.1,.1),
labeltype = "custom",
custom.labels = name_26,
main = "Difference in topic proportions: urban vs. rural",
xlab = "Rural ... Urban")
plot.estimateEffect(int_effects,
covariate = "DQ6.Where.do.you.live.",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.2,.2),
main = "Ethnicity/International Relations by region",
xlab = "Topic Proportions")
plot.estimateEffect(int_effects,
covariate = "DQ6.Where.do.you.live.",
moderator = "DQ5.Live",
moderator.value = "urban area",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.2,.2),
main = "Ethnicity/International Relations by region (urban areas only)",
xlab = "Topic Proportions")
plot.estimateEffect(int_effects,
covariate = "DQ6.Where.do.you.live.",
moderator = "DQ5.Live",
moderator.value = "rural area",
topics = c(5,13,19),
method = "pointestimate",
labeltype = "custom",
custom.labels = regions,
xlim = c(-.2,.2),
main = "Ethnicity/International Relations by region (rural areas only)",
xlab = "Topic Proportions")
```
##  Controls
set.seed(1)
kRange <- 5:50 # Number of topics to optimise.
##   Prevalence Covariates
stm_form <- formula(~ Q1.Feeling.about.example +
Q2.How.common +
Q3.Who.should.hear_everyone +
Q3.Who.should.hear_NGOs +
Q3.Who.should.hear_my.friends.and.family +
Q3.Who.should.hear_international.community +
Q3.Who.should.hear_my.government +
Q3.Who.should.hear_no.one.special +
Q5.Story.involves_security +
Q5.Story.involves_education +
Q5.Story.involves_politics +
Q5.Story.involves_violence +
Q5.Story.involves_business.trade +
Q5.Story.involves_justice +
Q5.Story.involves_democracy +
Q5.Story.involves_human.rights +
Q5.Story.involves_conflict +
Q5.Story.involves_relations.with.other.countries +
Q5.Story.involves_cooperation +
Q5.Story.involves_other +
Q6.Who.impacted.experience_ambitions.for.the.future +
Q6.Who.impacted.experience_recreation.leisure.activities +
Q6.Who.impacted.experience_calls.for.change +
Q6.Who.impacted.experience_freedom.of.movement +
Q6.Who.impacted.experience_utilities +
Q6.Who.impacted.experience_respect.tolerance +
Q6.Who.impacted.experience_trust +
Q6.Who.impacted.experience_freedom.of.speech +
Q6.Who.impacted.experience_employment.opportunities +
Q6.Who.impacted.experience_other +
DQ1.Age +
DQ2.Gender +
DQ3.Education +
DQ5.Live +
DQ6.Where.do.you.live. +
DQ7.Language)
##  Preprocessing
# Change NAs to 0s. (stm uses glmnet, hates NAs)
x <- clean[,c(55:106,110:117,123:127)]
x <- apply(x,1:2, function(x) if (is.na(x)) x <- 0 else x <- 1)
clean[,c(55:106,110:117,123:127)] <- x
# Text processing
pre_stm <- textProcessor(documents=clean$texts_eng,metadata=clean)
docs_removed <- pre_stm$docs.removed
docs <- pre_stm$documents
pre_stm <- prepDocuments(docs, pre_stm$vocab, pre_stm$meta)
docs <- pre_stm$documents
vocab <- pre_stm$vocab
meta <-pre_stm$meta
##  Semi-automated K Selection
##  Choose range of possible K from performance of residuals and coherence-exclusivity frontier.
if (run_searchK == 1) {
start <- Sys.time()
model_diag <- searchK(pre_stm$documents,
pre_stm$vocab,
K = kRange,
prevalence = stm_form,
data = meta,
init.type = "Spectral")
finish <- Sys.time()
elapsed <- start - finish
run <- substr(Sys.time(),1,16)
run <- sub(" ","_",run)
run <- sub(":","-",run)
save("model_diag", file = paste0(wd,"/output/model_diag_",run,".RData"))
} else {
##  OR load previous searchK() diagnostics
load(paste0(wd,"/output/model_diag_2016-08-21_05-52.RData"))
}
##  Plot coherence-exclusivity frontier to approximate range of optimal K.
kRange <- 5:50
exc <- model_diag$results$exclus
coh <- model_diag$results$semcoh
# labels <- transpose(lapply(kRange, function(kRange) paste("K =",kRange)))[[1]]
ce_mat <- data.frame(coh=coh,exc=exc)
best_K <- rev(sort(lm(exc ~ coh)$residuals)) # N.B. Names in this vector are positions in the vector, not K values
ce_plot <- ggplot(ce_mat,aes(coh,exc)) +
geom_point(size = 2.5) +
geom_point(data = ce_mat[as.numeric(names(best_K)[1:10]),], aes(coh,exc), size = 2.5, colour = "red") +
geom_text(aes(label = as.character(kRange)),vjust = 1.5, size = 6) +
geom_smooth(method = lm, se = FALSE) +
labs(x = "Semantic Coherence",y = "Exclusivity") +
ggtitle("Coherence-Exclusivity Frontier") +
theme(
title = element_text(size = 30),
axis.title = element_text(size = 22)
)
# savePlot(filename = paste0(wd,"/output/"))
# Plot residuals by K
res <- model_diag$results$residual
res_mat <- data.frame(k=5:50,res)
res_plot <- ggplot(res_mat,aes(k,res)) +
geom_line() +
geom_point(size = 4) +
geom_point(data = res_mat[17:27,], aes(k,res), size = 3, colour = "red") +
labs(x = "Number of Topics (K)",y = "Residuals") +
ggtitle("Residuals") +
theme(
title = element_text(size = 30),
axis.title = element_text(size = 22)
)
##  Manually assess highest performing models to choose optimal K.
## 10 K values with performance on coherence-exclusivity frontier.
knames <- transpose(lapply(as.numeric(names(best_K)), function(best_K) best_K + 4))
best_K <- transpose(lapply(best_K, function(best_K) best_K + 4))[[1]]
names(best_K) <- knames[[1]]
kRange <- best_K[1:10]
##  Of those 10 models, 5 are in the range where residuals are minimized (K = 21,...,31).
kRange <- c(21,23,24,25,26)
if (run_searchK == 1){
i <- 0
for (k in kRange){
K <- k
i <- i+1
assign(paste0("stm_K",K),stm(pre_stm$documents,
pre_stm$vocab,
K = K,
prevalence = stm_form,
data = meta,
init.type = "Spectral"))
assign(paste0("wordprob_K",K),labelTopics(get(paste0("stm_K",K)), n = 7))
assign(paste0("docprob_K",K),findThoughts(get(paste0("stm_K",K)), n = 10))
kdocs <- findThoughts(get(paste0("stm_K",K)),texts=as.character(clean$texts_eng[-docs_removed]), n = 5)$docs
topic_mat <- data.frame(matrix(NA, nrow = length(kdocs), ncol = length(kdocs[[1]])))
for(i in 1:length(kdocs)){
topic_mat[i,] <- kdocs[[i]]
}
assign(paste0("topic_mat",K),topic_mat)
run <- substr(Sys.time(),1,16)
run <- sub(" ","_",run)
run <- sub(":","-",run)
# write.csv(topic_mat, file = paste0(wd,"/output/topics_K",K,"_",run,".csv"))
# write(capture.output(get(paste0("wordprob_K",K))), file = paste0(wd,"/output/words_K",K,"_",run,".txt"))
}
save(list = c("stm_K21","stm_K23","stm_K24","stm_K25","stm_K26"),
file = paste0(wd,"/output/autoselected_models.RData"))
} else {
load(paste0(wd,"/output/autoselected_models.RData"))
}
##  Chains are number of highest FREX scoring words that could be "chained"
##  togther semantically by human judgement (out of top 7 FREX words)
##  Names summarise the topic based on the FREX chains.
chain_21 <- c(4,3,5,7,4,3,3,6,6,5,
5,6,3,4,6,5,4,7,2,5,2)
name_21 <- c("kyrgyzstan","hospital","foreign relations","election/voting","trade/customs","water",
"youth","law & order","transport/infrastructure","utilities","agriculture","marriage/family",
"school/new","election/politics","dependents","university/sport","land","marriage/girls",
"uzbekistan/border","school","bad")
chain_23 <- c(4,4,7,7,6,3,1,6,6,5,
6,7,4,3,6,6,6,6,5,4,
6,7,4)
name_23 <- c("kyrgyzstan","hospital","border/tajikistan","election/voting","trade/kazakhstan","water",
"youth","law & order", "waste/infrastructure","utilities","agriculture","marriage/family",
"school/new","election/politics","dependents","university/sport","land","family/relations",
"citizenship/uzbekistan","school","transport/infrastructure","girls/marriage","agriculture/rural")
chain_24 <- c(4,3,5,7,5,6,3,7,6,6,
3,7,3,4,4,6,6,6,6,4,
7,6,7,2)
name_24 <- c("kyrgyzstan","friend/favour","foreign relations","election/voting","trade/customs","water",
"youth","law & order","city/infrastructure","utilities","finance/emigration","family/marriage",
"school/new","elections/politics","dependents","university/sport","land/rural","family/relations",
"citizenship/uzbekistan","school","transport/infrastructure","girls/marriage","agriculture/trade","jobs/moscow")
chain_25 <- c(3,3,7,7,7,3,3,6,6,5,
7,7,3,4,6,5,4,6,3,5,
6,7,7,7,2)
name_25 <- c("kyrgyzstan","health","nation/ethnicity","election/voting","trade/kazakhstan","water",
"youth","law & order","city/infrastructure","utilities","finance/agriculture","family/marriage",
"school","elections/politics","dependents","university","rural","family/relations",
"citizenship/uzbekistan","school","transport/infrastructure","girls/marriage","agriculture/trade","jobs/moscow",
"new facilities")
chain_26 <- c(6,0,6,7,6,4,3,7,6,6,
6,7,4,5,6,7,5,7,3,5,
7,7,7,7,4,3)
name_26 <- c("kyrgyzstan/emigration","<Non discernable>","nation/peace","election/voting","trade/kazakhstan","water",
"youth","law & order","city/infrastructure","utilities","finance/agriculture","family/marriage",
"tajikistan/women","elections/politics","dependents","university/corruption","rural","family/relations",
"uzbekistan/citizenship","education","transport/infrastructure","girls/marriage","agriculture/trade","jobs/russia",
"new facilities", "school")
chain_mat <- matrix(NA,nrow = 26,ncol = 5)
chain_mat[1:21,1] <- chain_21
chain_mat[1:23,2] <- chain_23
chain_mat[1:24,3] <- chain_24
chain_mat[1:25,4] <- chain_25
chain_mat[1:26,5] <- chain_26
colnames(chain_mat) <- c("K21","K23","K24","K25","K26")
means <- apply(chain_mat,2, function(chain_mat) mean(chain_mat,na.rm = TRUE))
name_mat <- matrix(NA,nrow = 26,ncol = 5)
name_mat[1:21,1] <- name_21
name_mat[1:23,2] <- name_23
name_mat[1:24,3] <- name_24
name_mat[1:25,4] <- name_25
name_mat[1:26,5] <- name_26
colnames(name_mat) <- c("K21","K23","K24","K25","K26")
K <- 26 # Choose final K
est_form <- formula(c("1:26 ~ ",as.character(stm_form)[2]))
int_form <- formula(paste0(" ~ ", as.character(stm_form)[2]," + DQ5.Live * DQ6.Where.do.you.live. + Q1.Feeling.about.example * Q2.How.common + DQ6.Where.do.you.live. * DQ7.Language"))
if (run_stm == 1) {
final_stm <- stm(docs, vocab, K, prevalence = stm_form, data = droplevels(meta), init.type = "Spectral")
int_model <- stm(docs, vocab, K, prevalence = int_form, data = droplevels(meta), init.type = "Spectral")
save("int_model", file = paste0(wd,"/output/interaction_stm.RData"))
save("final_stm",file = paste0(wd,"/output/final_stm.RData"))
} else {
load(paste0(wd,"/output/final_stm.RData"))
load(paste0(wd,"/output/interaction_stm.RData"))
}
est_form2 <- formula(paste("1:26 ~ ", as.character(int_form)[2]))
# lda <- selectModel(docs, vocab, K, prevalence = stm_form, data = meta, init.type = "Spectral")
##  Run this overnight?
##  Top Topics
topic_summary <- plot.STM(final_stm, type = "summary", topics = 1:K, custom.labels = name_26)
##  Prevalence Analysis
##  Attach document-topic proportions to original df.
doctop <- final_stm$theta
colnames(doctop) <- name_26
topic_meta <- data.frame(clean[-docs_removed,],doctop)
tq <- summary(topic_meta$girls.marriage)[5]
topquart <- topic_meta[which(topic_meta$girls.marriage > tq),]
topic_form <- "kyrgyzstan.emigration +
nation.peace +
election.voting +
trade.kazakhstan +
water +
youth +
law...order +
city.infrastructure +
utilities +
finance.agriculture +
family.marriage +
tajikistan.women +
elections.politics +
dependents +
university.corruption +
rural +
family.relations +
uzbekistan.citizenship +
education +
transport.infrastructure +
girls.marriage +
agriculture.trade +
jobs.russia +
new.facilities +
school"
q_form <- "Q7.Score + Q2.How.common + Q5.Story.involves_security + Q5.Story.involves_education + Q5.Story.involves_politics + Q5.Story.involves_violence + Q5.Story.involves_business.trade + Q5.Story.involves_justice + Q5.Story.involves_democracy + Q5.Story.involves_human.rights + Q5.Story.involves_conflict + Q5.Story.involves_relations.with.other.countries + Q5.Story.involves_cooperation + Q5.Story.involves_other"
dq_form <- "DQ1.Age + DQ2.Gender + DQ3.Education + DQ5.Live + DQ6.Where.do.you.live. + DQ7.Language"
ggtern(data=topquart,aes(T2.People.affected.by.information,
T2.People.affected.by.actions.events,
T2.People.affected.by.beliefs.traditional.values,
color = topquart$Q7.Score)) +
geom_point(size=2) +
scale_fill_brewer(palette = "Spectral", guide = "legend")
lm1 <- regsubsets(x = formula(paste0("girls.marriage ~ ",paste(q_form,"+",dq_form))),
data = topic_meta,
nbest = 1,
nvmax = 26,
method = "forward")
lm2 <- lm(girls.marriage ~ Q5.Story.involves_politics + Q5.Story.involves_violence, data = topic_meta)
lm3 <- regsubsets(x = formula(paste0("youth ~ ",paste(q_form,"+",dq_form))),
data = topic_meta,
nbest = 1,
nvmax = 26,
method = "forward")
lm4 <- lm(youth ~ Q5.Story.involves_politics + Q5.Story.involves_human.rights + DQ1.Age + DQ2.Gender, data = topic_meta)
lm5 <- regsubsets(x = formula(paste("uzbekistan.citizenship ~ ",q_form,"+",dq_form)),
data = topic_meta,
nbest = 1,
nvmax = 26,
method = "forward")
lm6 <- lm(uzbekistan.citizenship ~ DQ7.Language + Q2.How.common + Q5.Story.involves_conflict + Q5.Story.involves_cooperation + Q7.Score, data = topic_meta)
lm7 <- regsubsets(x = formula(paste("election.voting ~ ",q_form,"+",dq_form)),
data = topic_meta,
nbest = 1,
nvmax = 26,
method = "forward")
lm8 <- lm(election.voting ~ DQ1.Age + DQ3.Education + Q7.Score + Q5.Story.involves_security + Q5.Story.involves_education + Q5.Story.involves_politics + Q5.Story.involves_violence + Q5.Story.involves_business.trade + Q5.Story.involves_justice + Q5.Story.involves_democracy + Q5.Story.involves_human.rights + Q5.Story.involves_conflict + Q5.Story.involves_relations.with.other.countries + Q5.Story.involves_cooperation + Q5.Story.involves_other, data = topic_meta)
lm9 <- regsubsets(x = formula(paste("elections.politics ~ ",q_form,"+",dq_form)),
data = topic_meta,
nbest = 1,
nvmax = 26,
method = "forward")
lm10 <- lm(elections.politics ~ DQ2.Gender + DQ7.Language + Q5.Story.involves_security + Q5.Story.involves_education + Q5.Story.involves_politics + Q5.Story.involves_violence + Q5.Story.involves_business.trade + Q5.Story.involves_justice + Q5.Story.involves_democracy + Q5.Story.involves_human.rights + Q5.Story.involves_conflict + Q5.Story.involves_relations.with.other.countries + Q5.Story.involves_cooperation + Q5.Story.involves_other, data = topic_meta)
lm11 <- regsubsets(x = formula(paste("transport.infrastructure ~ ",q_form,"+",dq_form)),
data = topic_meta,
nbest = 1,
nvmax = 26,
method = "forward")
lm12 <- lm(transport.infrastructure ~ DQ5.Live + DQ6.Where.do.you.live. + DQ1.Age + Q5.Story.involves_security + Q5.Story.involves_education + Q5.Story.involves_politics + Q5.Story.involves_violence + Q5.Story.involves_business.trade + Q5.Story.involves_justice + Q5.Story.involves_democracy + Q5.Story.involves_human.rights + Q5.Story.involves_conflict + Q5.Story.involves_relations.with.other.countries + Q5.Story.involves_cooperation + Q5.Story.involves_other, data = topic_meta)
##  topics ~ topics!!
?stdin
stdin("http://genius.com/Nas-the-world-is-yours-lyrics")
stdin(con = "http://genius.com/Nas-the-world-is-yours-lyrics")
stdin(con = http://genius.com/Nas-the-world-is-yours-lyrics)
x <- LETTER[1:10]
x <- LETTERS[1:10]
x
grep("L",x)
?grep
grep("L",x, value = TRUE)
match("L", x)
?match
match("L", x, nomatch = NULL)
as.integer(NULL)
y <- as.integer(NULL)
is.null(y)
?dimnames
z <- c(x,NA, NA)
!is.na(z)
z[!is.na(z)]
renderDataTable
?renderDataTable
library(shiny)
?renderDataTable
setwd("C:/Users/charl/Dropbox/UNDP & Dissertation/Deliverable_Master")
load("C:/Users/charl/Dropbox/UNDP & Dissertation/Deliverable_Master/temp/rows.RData")
View(rows)
rm(rows)
